# =============================================================================
# Enterprise SLM-First Knowledge Copilot - Environment Configuration
# =============================================================================
# Copy this file to .env and update with your values

# =============================================================================
# Application Environment
# =============================================================================
ENVIRONMENT=development
DEBUG=true
LOG_LEVEL=INFO

# =============================================================================
# PostgreSQL Configuration
# =============================================================================
POSTGRES_USER=slm_user
POSTGRES_PASSWORD=slm_password
POSTGRES_DB=slm_knowledge
POSTGRES_PORT=5432
DATABASE_URL=postgresql+asyncpg://slm_user:slm_password@postgres:5432/slm_knowledge

# =============================================================================
# Redis Configuration
# =============================================================================
REDIS_PORT=6379
REDIS_URL=redis://redis:6379/0

# =============================================================================
# Qdrant Configuration
# =============================================================================
QDRANT_PORT=6333
QDRANT_GRPC_PORT=6334
QDRANT_URL=http://qdrant:6333
QDRANT_COLLECTION=documents

# =============================================================================
# vLLM Configuration (Inference Engine)
# =============================================================================
VLLM_PORT=8000
VLLM_MODEL=Qwen/Qwen2.5-1.5B-Instruct
VLLM_GPU_MEMORY_UTILIZATION=0.85
VLLM_MAX_MODEL_LEN=2048

# =============================================================================
# Service Ports (Consolidated: 3 services)
# =============================================================================
API_SERVICE_PORT=8000
KNOWLEDGE_SERVICE_PORT=8001
INFERENCE_SERVICE_PORT=8002

# =============================================================================
# Service URLs (Internal)
# =============================================================================
KNOWLEDGE_SERVICE_URL=http://knowledge-service:8000
INFERENCE_SERVICE_URL=http://inference-service:8000

# =============================================================================
# Authentication & Security
# =============================================================================
JWT_SECRET_KEY=change-this-to-a-random-secret-key-in-production
JWT_ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=30

# =============================================================================
# ML Models
# =============================================================================
EMBEDDING_MODEL=BAAI/bge-small-en-v1.5
RERANKER_MODEL=cross-encoder/ms-marco-MiniLM-L-6-v2
LLM_MODEL=Qwen/Qwen2.5-1.5B-Instruct

# =============================================================================
# Query Optimization
# =============================================================================
CONFIDENCE_THRESHOLD=0.6

# =============================================================================
# Rate Limiting
# =============================================================================
RATE_LIMIT_REQUESTS=100
RATE_LIMIT_WINDOW=60

# =============================================================================
# Document Ingestion
# =============================================================================
CHUNK_SIZE=512
CHUNK_OVERLAP=50
MAX_FILE_SIZE_MB=50

# =============================================================================
# Caching TTL (in seconds)
# =============================================================================
CACHE_EMBEDDING_TTL=86400      # 24 hours
CACHE_SEARCH_TTL=3600          # 1 hour
CACHE_LLM_RESPONSE_TTL=86400   # 24 hours

# =============================================================================
# Prometheus Metrics
# =============================================================================
METRICS_ENABLED=true
METRICS_PORT=9090

# =============================================================================
# OpenTelemetry (Optional)
# =============================================================================
OTEL_EXPORTER_OTLP_ENDPOINT=http://otel-collector:4317
OTEL_SERVICE_NAME=slm-knowledge-copilot
